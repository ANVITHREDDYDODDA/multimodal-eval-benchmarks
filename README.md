# multimodal-eval-benchmarks
Work-in-progress benchmark &amp; evaluation suite for multimodal/generative media models—task sets, scoring metrics, and human preference rubrics (started Dec 18, 2025).

## Progress log
- Day 1: defined benchmark scope + failure taxonomy; drafted v0.1 tasks; created human rubric outline
- Next 48 hours: add 30–50 prompts, rater instructions + QA checks, and a scoring template
